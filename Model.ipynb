{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PepiMartin28/FootballLogos-VAE/blob/develop/Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Notebook utilizada para crear el modelo y entrenarlo"
      ],
      "metadata": {
        "id": "tcYMMkSmIHaR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch;\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils\n",
        "from torch.utils.data import Dataset\n",
        "import torch.distributions\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "qioMUoBO5V-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Descargamos los logos de los equipos"
      ],
      "metadata": {
        "id": "IezYzUz4jBLb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2uvln2OQiSnP"
      },
      "outputs": [],
      "source": [
        "!gdown https://drive.google.com/uc?id=1yXdPhk-OZ-lhGMYbsP_FHc-22Xhsu5Ux\n",
        "!gdown https://drive.google.com/uc?id=1x-CtdUFfrhAqsHAILxdqkAj9fUG-xTgQ\n",
        "!unzip logos.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0e6S6PGl56t",
        "outputId": "aecf9130-d892-4814-a13e-2039a226c2d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Armamos el dataset"
      ],
      "metadata": {
        "id": "rrkqpFcp4yoV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LogoDataset(Dataset):\n",
        "  def __init__(self, annotations_file):\n",
        "    self.archivo = pd.read_csv(annotations_file)\n",
        "    self.transform = transforms.Compose([\n",
        "            transforms.Resize((200, 200)),\n",
        "            transforms.ToTensor(),\n",
        "        ])\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.archivo[\"id\"])\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    label = self.archivo.loc[idx,\"name\"]\n",
        "    img_path = self.archivo.loc[idx,\"img_dir\"]\n",
        "    image = Image.open(img_path).convert(\"RGBA\")\n",
        "    image = self.transform(image)\n",
        "    return image, label\n",
        "\n",
        "dataset = LogoDataset(\"/content/logos/logos.csv\")\n",
        "\n",
        "dataloader = torch.utils.data.DataLoader(\n",
        "        dataset,\n",
        "        batch_size=128,\n",
        "        shuffle=True,)"
      ],
      "metadata": {
        "id": "11YKP8qY4yK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Definimos el modelo"
      ],
      "metadata": {
        "id": "vlDhAD2eUVjQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AUG_block(nn.Module):\n",
        "    def __init__(self, out_channels, in_channels=4, kernel_size=5, strides=2,\n",
        "                 padding=1, **kwargs):\n",
        "        super(AUG_block, self).__init__(**kwargs)\n",
        "        self.conv2d_trans = nn.ConvTranspose2d(in_channels, out_channels,\n",
        "                                kernel_size, strides, padding, bias=False)\n",
        "        self.batch_norm = nn.BatchNorm2d(out_channels)\n",
        "        self.activation = nn.ReLU()\n",
        "\n",
        "    def forward(self, X):\n",
        "        return self.activation(self.batch_norm(self.conv2d_trans(X)))"
      ],
      "metadata": {
        "id": "bUHTjAfCUF6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DEC_block(nn.Module):\n",
        "    def __init__(self, out_channels, in_channels=4, kernel_size=5, strides=2,\n",
        "                padding=1, alpha=0.2, **kwargs):\n",
        "        super(DEC_block, self).__init__(**kwargs)\n",
        "        self.conv2d = nn.Conv2d(in_channels, out_channels, kernel_size,\n",
        "                                strides, padding, bias=False)\n",
        "        self.batch_norm = nn.BatchNorm2d(out_channels)\n",
        "        self.activation = nn.LeakyReLU(alpha, inplace=True)\n",
        "\n",
        "    def forward(self, X):\n",
        "        return self.activation(self.batch_norm(self.conv2d(X)))"
      ],
      "metadata": {
        "id": "XWsl6HpfUGqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_G = 32\n",
        "\n",
        "class Variational_Encoder(nn.Module):\n",
        "    def __init__(self, latent_dims, n_channels=4):\n",
        "        super(Variational_Encoder, self).__init__()\n",
        "        self.conv_seq = nn.Sequential(\n",
        "            DEC_block(in_channels=n_channels, out_channels=n_G),\n",
        "            DEC_block(in_channels=n_G, out_channels=n_G*2),\n",
        "            DEC_block(in_channels=n_G*2, out_channels=n_G*4),\n",
        "            DEC_block(in_channels=n_G*4, out_channels=n_G*8),\n",
        "            DEC_block(in_channels=n_G*8, out_channels=n_G*16),\n",
        "            nn.AdaptiveMaxPool2d((1, 1)),\n",
        "            nn.Flatten(),\n",
        "            nn.LazyLinear(latent_dims)\n",
        "        )\n",
        "        self.linear3 = nn.LazyLinear(latent_dims)\n",
        "        self.linear4 = nn.LazyLinear(latent_dims)\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.conv_seq(x)\n",
        "        media = self.linear3(z)\n",
        "        log_var = F.relu(self.linear4(z))\n",
        "        std = torch.exp(0.5*log_var)\n",
        "        eps = torch.randn_like(std)\n",
        "        latente = eps.mul(std).add_(media)\n",
        "        return (latente, media, log_var)"
      ],
      "metadata": {
        "id": "23aEquN9UJWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, latent_dims, n_channels=4):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.seq = nn.Sequential(\n",
        "            AUG_block(in_channels=latent_dims, out_channels=n_G*16, strides=1, padding=0), #[5, 5]\n",
        "            AUG_block(in_channels=n_G*16, out_channels=n_G*8), #[11, 11]\n",
        "            AUG_block(in_channels=n_G*8, out_channels=n_G*4), #[23, 23]\n",
        "            AUG_block(in_channels=n_G*4, out_channels=n_G*2), #[47, 47]\n",
        "            AUG_block(in_channels=n_G*2, out_channels=n_G, strides=3, padding = 9), #[125, 125]\n",
        "            nn.ConvTranspose2d(in_channels=n_G, out_channels=4, kernel_size=2, stride=2, padding=25, bias=False), #[200, 200]\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        return self.seq(z)"
      ],
      "metadata": {
        "id": "hF7Bb3LIUOLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Variational_Autoencoder(nn.Module):\n",
        "    def __init__(self, latent_dims, n_channels=4):\n",
        "        super(Variational_Autoencoder, self).__init__()\n",
        "        self.encoder = Variational_Encoder(latent_dims, n_channels)\n",
        "        self.decoder = Decoder(latent_dims, n_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        z, media, log_var = self.encoder(x)\n",
        "        z = z.unsqueeze(2).unsqueeze(3)\n",
        "        return self.decoder(z), media, log_var"
      ],
      "metadata": {
        "id": "Lc5ifVFXURQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vae_loss(x, x_hat, media, log_var):\n",
        "  reconstruction_loss = F.binary_cross_entropy(x_hat, x, reduction='sum')\n",
        "  #1 + codings_log_var - K.exp(codings_log_var) - K.square(codings_mean)\n",
        "  latent_loss = -0.5 * torch.sum(1 + log_var - log_var.exp() - media.pow(2))\n",
        "  return reconstruction_loss + latent_loss"
      ],
      "metadata": {
        "id": "xu1JEaQ8a52y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Entrenamos el modelo"
      ],
      "metadata": {
        "id": "xMOvGstUH-hw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(autoencoder, data, epochs=10000):\n",
        "    opt = torch.optim.Adam(autoencoder.parameters())\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        L = 0.0\n",
        "        N = 0\n",
        "        for x, y in dataloader:\n",
        "            x = x.to(device) # GPU\n",
        "            opt.zero_grad()\n",
        "            x_hat, media, std = autoencoder(x)\n",
        "            l = vae_loss(x,x_hat, media, std)\n",
        "            l.backward()\n",
        "            opt.step()\n",
        "            L += l.sum()\n",
        "            N += l.numel()\n",
        "        if (epoch+1) % 50 == 0:\n",
        "          print(f'epoch {epoch + 1}, loss {(L/N):f}')\n",
        "\n",
        "        if (epoch+1) % 100 == 0:\n",
        "          torch.save(vae.state_dict(), f'/content/drive/MyDrive/vae-weights-700D-epoch({epoch+1}).params')\n"
      ],
      "metadata": {
        "id": "wsNe6Gjrn48g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dims = 700\n",
        "vae = Variational_Autoencoder(latent_dims).to(device) # GPU\n",
        "vae.load_state_dict(torch.load('/content/vae-weights-700DV5.params'))\n",
        "vae.train()"
      ],
      "metadata": {
        "id": "I7i4tPbe--Gf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(vae, dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQNpjx1M_g3t",
        "outputId": "41e516a1-b78a-4bae-92bb-781f2aa2f341"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 50, loss 4611406.500000\n",
            "epoch 100, loss 4608636.500000\n",
            "epoch 150, loss 4607030.000000\n",
            "epoch 200, loss 4604271.000000\n",
            "epoch 250, loss 4604197.500000\n",
            "epoch 300, loss 4603245.500000\n",
            "epoch 350, loss 4601725.000000\n",
            "epoch 400, loss 4599759.500000\n",
            "epoch 450, loss 4600329.000000\n",
            "epoch 500, loss 4598127.500000\n",
            "epoch 550, loss 4598709.500000\n",
            "epoch 600, loss 4596523.000000\n",
            "epoch 650, loss 4595637.000000\n",
            "epoch 700, loss 4596529.500000\n",
            "epoch 750, loss 4593616.500000\n",
            "epoch 800, loss 4591520.000000\n",
            "epoch 850, loss 4592373.000000\n",
            "epoch 900, loss 4592435.500000\n"
          ]
        }
      ]
    }
  ]
}